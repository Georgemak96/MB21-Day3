---
title: "Covid vaccine regression"
author: ""
date: "08/02/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```

## Regression problem

- We will run regression and other related models for Covid-19 vaccination data

## Libiraries

- We will use the following packages

```{r}
library(tidyverse)
library(caret)
library(glmnet)
```

## Load data

We will use the following data. It is a combined dataset from three data sources we have been using. The code for processing is available at `data_prep/data_preparation.R`.

```{r}
data_vac <- read_csv("data/vaccine-data.csv.gz") 
```


## Check data

Let's have a cursory look at the data, especially check the distribution of the output variable `Booster_Doses_18Plus_Vax_Pct` Do we need conversion?

### `head()`

```{r}
head(data_vac$Booster_Doses_18Plus_Vax_Pct)
class(data_vac$Booster_Doses_18Plus_Vax_Pct)
```

### Check the distribution of the output

```{r}
data_vac  %>% ggplot(aes(Booster_Doses_18Plus_Vax_Pct)) +
  geom_histogram()
##it needs to be done normal. Standardization would be a solution
```

```{r}

```


## Decide the variable to include as input

- There are 47 variables what are possible predictors? Especially:
  - trump_pct
  - demography: TotalPop, Men, Women, Hispanic, White, Black, Native, Asian, Pacific, VotingAgeCitizen, Income, IncomePerCap, Poverty, ChildPoverty, Professional, Service, Office, Construction, Production, Drive, Carpool, Transit, Walk, OtherTransp, WorkAtHome, MeanCommute, Employed, PrivateWork, PublicWork, SelfEmployed, FamilyWork, Unemployment
- What do you think should be included as the inputs?


```{r}
#men, women, white-Asian, VotingAgeCitizen,Income,Poverty-Drive, PrivateWork-Unemployment
```

## Data preparation

Here we need to prepare the data, in particular:

1. Train-test split
2. Data preprocessing

Using `caret` (or something else if you like), prepare two datasets of pre-processed train/test data.

## Train-test split

```{r}
train <- sample(nrow(data_vac), nrow(data_vac)*.7)
data_vac_train <-data_vac %>% slice(train)
data_vac_test <- data_vac %>% slice(-train)
```

## Preprocess

```{r}
data_vac_prep<- preProcess(data_vac_train, method = c("center", "scale"))
data_vac_train_processed <- predict(data_vac_prep, data_vac_train) %>% as.data.frame()
data_vac_test_processed <- predict(data_vac_prep, data_vac_test) %>% as.data.frame()
class(data_vac_train_processed)
```


## Analysis

### Linear regression

- Run linear regression 
- Evaluate the model

```{r}
reg_model <- lm(Booster_Doses_18Plus_Vax_Pct ~ Men+ Women+White+Asian+Black+Hispanic+Pacific+ VotingAgeCitizen + Income+ IncomePerCap+ Poverty+ ChildPoverty+ Professional+ Service+ Office+ Construction+ Production+Employed+ PrivateWork+ PublicWork+ SelfEmployed+ FamilyWork+ Unemployment +TotalPop+Drive+ Carpool+ Transit+ Walk+ OtherTransp+ WorkAtHome+ MeanCommute, data= data_vac_train_processed)
summary(reg_model)
predictions_test<- predict(reg_model, data_vac_test_processed)
rmse_test <- sqrt(mean((data_vac_test_processed$pct_trump - predictions_test)^2))
predictions_train <- predict(reg_model)
rmse_train <- sqrt(mean((data_vac_train_processed$pct_trump- predictions_train)^2))
```
```{r}

```

### Additional movel evaluations

Using the linear regression model as the baseline we attempt two things:

1. Is it possible to improve the prediction using more flexible models?
  - KNN-regression
  - Or regression model variant of models covered in classificaiton section. 
    - For example:
      - svm: svmPoly, svmRadial works both regression and classification (svmPoly may take quite long time as the number of tuning paramters are many.)
      - trees: rf
      


```{r}
tune_grid = expand.grid(k = c(3,4,5,7,9,10,15,20,25,30))
tr = trainControl(method = "repeatedcv", number = 5, repeats = 3)
data_vac_train_processed <- data_vac_train_processed %>% na.omit()
knn_model <- train(Booster_Doses_18Plus_Vax_Pct ~ Men+ Women+White+Asian+Black+Hispanic+Pacific+ VotingAgeCitizen + Income+ IncomePerCap+ Poverty+ ChildPoverty+ Professional+ Service+ Office+ Construction+ Production+Employed+ PrivateWork+ PublicWork+ SelfEmployed+ FamilyWork+ Unemployment +TotalPop+Drive+ Carpool+ Transit+ Walk+ OtherTransp+ WorkAtHome+ MeanCommute, data= data_vac_train_processed, method = "knn", trControl = tr, tuneGrid = tune_grid)
predictions_test <- predict(knn_model, data_vac_test_processed)
rmse_knn_test = sqrt(mean((data_vac_test_processed$pct_trump - predictions_test)^2))
predictions_train <- predict(knn_model)
rmse_knn_train <- sqrt(mean((data_vac_train_processed$pct_trump - predictions_train)^2))
plot(knn_model)

```

### SVM with Radial Kernel

```{r}
tr = trainControl(method = "repeatedcv", number = 5, repeats = 3)
svm_model <- train(Booster_Doses_18Plus_Vax_Pct ~ Men+ Women+White+Asian+Black+Hispanic+Pacific+ VotingAgeCitizen + Income+ IncomePerCap+ Poverty+ ChildPoverty+ Professional+ Service+ Office+ Construction+ Production+Employed+ PrivateWork+ PublicWork+ SelfEmployed+ FamilyWork+ Unemployment +TotalPop+Drive+ Carpool+ Transit+ Walk+ OtherTransp+ WorkAtHome+ MeanCommute, data= data_vac_train_processed, method="svmRadial", trainControl = tr)
predictions_test <- predict(svm_model, data_vac_test_processed)
rmse_svm_test = sqrt(mean((data_vac_test_processed$pct_trump - predictions_test)^2))
predictions_train <- predict(svm_model)
rmse_svm_train <- sqrt(mean((data_vac_train_processed$pct_trump - predictions_train)^2))
```


## LASSO and ridge regression

- Now, let's run LASSO and/or Ridge regression. 
- What do you find? 
  - Shrinkage of the coefficients

### LASSO Outcome

```{r}
data_vac_train_processed_x <- data_vac_train_processed %>% select(Men, Women,White,Asian,Black,Hispanic,Pacific,VotingAgeCitizen,Income,IncomePerCap, Poverty,ChildPoverty,Professional,Service,Office,Construction,Production,Employed,PrivateWork,PublicWork,SelfEmployed, FamilyWork, Unemployment,TotalPop,Drive, Carpool, Transit, Walk, OtherTransp,WorkAtHome, MeanCommute) %>% as.matrix()
data_vac_train_processed_y = data_vac_train_processed$Booster_Doses_18Plus_Vax_Pct
data_vac_test_processed_x <- data_vac_test_processed %>% select(Men, Women,White,Asian,Black,Hispanic,Pacific,VotingAgeCitizen,Income,IncomePerCap, Poverty,ChildPoverty,Professional,Service,Office,Construction,Production,Employed,PrivateWork,PublicWork,SelfEmployed, FamilyWork, Unemployment,TotalPop,Drive, Carpool, Transit, Walk, OtherTransp,WorkAtHome, MeanCommute) %>% as.matrix()
data_vac_test_processed_y <-data_vac_test_processed$Booster_Doses_18Plus_Vax_Pct
lasso_reg <- cv.glmnet(data_vac_train_processed_x, data_vac_train_processed_y, alpha = 1,  type.measure = "mse", family = "gaussian")
plot(lasso_reg)
bestlambda <- lasso_reg$lambda.1se
predictions_train <- predict(lasso_reg,newx =data_vac_train_processed_x, s =bestlambda)
rmse_lasso_train = sqrt(mean((data_vac_train_processed_y - predictions_train)^2))
predictions_test <- predict(lasso_reg,data_vac_test_processed_x,s=bestlambda )
rmse_lasso_test <- sqrt(mean(( data_vac_test_processed_y- predictions_test)^2, na.rm = TRUE))
coef(lasso_reg)
```

#### Plot with `plot_glmnet`

Shrinkage plot of `glmnet` is not informative as it won't show the variable name. Instead you can use `plot_glmnet` in `plotmo` package.

```{r}
library(plotmo)
plot_glmnet(lasso_reg$glmnet.fit, xvar = "lambda")
abline(v = log(lasso_reg$lambda.1se)) 
```



### Ridge regression outcome

```{r}
ridge_reg <- cv.glmnet(data_vac_train_processed_x, data_vac_train_processed_y, alpha = 0,  type.measure = "mse", family = "gaussian")
plot(ridge_reg)
bestlambda <- ridge_reg$lambda.1se
predictions_train <- predict(ridge_reg,newx =data_vac_train_processed_x, s =bestlambda)
rmse_ridge_train = sqrt(mean((data_vac_train_processed_y - predictions_train)^2))
predictions_test <- predict(ridge_reg,data_vac_test_processed_x,s=bestlambda )
rmse_ridge_test <- sqrt(mean(( data_vac_test_processed_y- predictions_test)^2,na.rm = TRUE))
coef(ridge_reg)

```

#### Plot with `plot_glmnet`

```{r}
plot_glmnet(ridge_reg$glmnet.fit, xvar = "lambda")
abline(v = log(lasso_reg$lambda.1se)) 
```

### Compare coefs: lm, lasso/ridge

Compare the cefficients across the models. What do you find?

```{r}
cbind(coef(reg_model), coef(lasso_reg), coef(ridge_reg)) 
###Final comparison
data.frame(rmse_train_regression = rmse_train, rmse_train_knn = rmse_knn_train, rmse_train_svm = rmse_svm_train, rmse_train_lasso = rmse_lasso_train, rmse_train_ridge = rmse_ridge_train)
data.frame(rmse_test_regression = rmse_test, rmse_test_knn = rmse_knn_test, rmse_test_svm = rmse_svm_test, rmse_test_lasso = rmse_lasso_test,rmse_test_ridge = rmse_ridge_test)
###in terms of bias knn regressionnn seems to had the lowestt 
###in terms of variance svm regression, as well as linear regression wins but by a narrowmarginn
```